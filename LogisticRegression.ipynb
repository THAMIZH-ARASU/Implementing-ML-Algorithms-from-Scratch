{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce8f24e9-9ec4-4429-84a9-b3a35aba6abf",
   "metadata": {},
   "source": [
    "# **Logistic Regression Overview**\n",
    "\n",
    "Logistic regression is a statistical and machine learning technique used for binary classification problems. It models the probability of a dependent variable belonging to a particular class based on one or more independent variables. Unlike linear regression, logistic regression outputs probabilities that can be mapped to class labels using a decision threshold.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb545c-c411-4bfc-9113-8a39ce61af03",
   "metadata": {},
   "source": [
    "## **Approximation**\n",
    "\n",
    "Logistic regression models the probability of the target variable belonging to a class as follows:\n",
    "\n",
    "## \\\\[ P(y=1|x) = \\sigma(wx + b) \\\\]\n",
    "## \\\\[ P(y=0|x) = 1 - \\sigma(wx + b) \\\\]\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- \\\\(\\sigma(z)\\\\): Sigmoid function, defined as \\\\(\\sigma(z) = \\frac{1}{1 + e^{-z}}\\\\), maps the linear combination of features to a probability.\n",
    "- \\\\(w\\\\): Weight (slope).\n",
    "- \\\\(x\\\\): Independent variable(s).\n",
    "- \\\\(b\\\\): Intercept (bias term).\n",
    "- \\\\(P(y=1|x)\\\\): Probability that the target variable \\\\(y\\\\) belongs to class 1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753f83a-8a36-454a-a48d-ce8d8bf1d8a0",
   "metadata": {},
   "source": [
    "## **Evaluation Metric**\n",
    "\n",
    "### **Log Loss (Cross-Entropy Loss):**\n",
    "\n",
    "Logistic regression optimizes the log loss function to measure the performance of the model:\n",
    "\n",
    "## \\\\[\n",
    "LogLoss = J(w, b) = -\\frac{1}{N} \\sum_{i=1}^N \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
    "\\\\]\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- \\\\(y_i\\\\): Actual class label of the \\\\(i\\\\)-th observation (0 or 1).\n",
    "- \\\\(\\hat{y}_i\\\\): Predicted probability for the \\\\(i\\\\)-th observation.\n",
    "- \\\\(N\\\\): Number of observations.\n",
    "\n",
    "---\n",
    "\n",
    "Log loss penalizes predictions that are far from the true labels, encouraging the model to output probabilities close to 0 or 1 for correct predictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8397f8e-73d0-447d-b81b-0b1f69d74b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef662f-2858-4dcd-83b2-d90074deac3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
